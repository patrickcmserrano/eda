# Wallet Core (EDA Study)

Eu desenvolvi este projeto como uma implementa√ß√£o de um n√∫cleo de transa√ß√µes financeiras (Wallet Core) baseada em Arquitetura Orientada a Eventos (EDA).

Ele nasceu como parte do desafio do curso Full Cycle, mas eu decidi utilizar uma stack moderna e funcional com **Clojure** e **Polylith**, focando em imutabilidade, modularidade e separation of concerns.

## üèó Arquitetura & Stack

Eu estruturei o projeto como um Monorepo modular gerenciado pelo **Polylith**:

* **Linguagem:** Clojure (JDK 17+)
* **Gerenciamento de Workspace:** Polylith (`poly`)
* **Valida√ß√£o de Dados:** Malli
* **Banco de Dados:** PostgreSQL 15 (via `next.jdbc` e `HoneySQL`)
* **Mensageria:** Apache Kafka (via `Jackdaw`)
* **API:** Jetty + Reitit + Ring

### Estrutura do Workspace


```text
bases/
  ‚îî‚îÄ‚îÄ wallet-api/       # API Gateway (REST -> Componentes)
  ‚îî‚îÄ‚îÄ balances-api/     # API Balance (REST + Kafka Consumer) [NOVO]
  ‚îî‚îÄ‚îÄ event-processor/  # Worker (Processamento Ass√≠ncrono)
components/
  ‚îú‚îÄ‚îÄ account/          # Dom√≠nio de Contas e Saldo
  ‚îú‚îÄ‚îÄ balance/          # Dom√≠nio de Leitura de Saldos (CQRS Projection) [NOVO]
  ‚îú‚îÄ‚îÄ client/           # Dom√≠nio de Clientes
  ‚îú‚îÄ‚îÄ transaction/      # Core: Atomicidade e Orquestra√ß√£o
  ‚îú‚îÄ‚îÄ database/         # Infra: Connection Pool e Migrations
  ‚îî‚îÄ‚îÄ kafka/            # Infra: Producers
projects/
  ‚îî‚îÄ‚îÄ wallet/           # Artefato Deploy√°vel (Wallet Core)
  ‚îî‚îÄ‚îÄ balances/         # Artefato Deploy√°vel (Balances Service) [NOVO]
```

## ‚úÖ Conformidade e Integridade do Sistema

Este projeto foi desenvolvido n√£o apenas como uma resposta aos diffs do desafio, mas como um sistema completo e resiliente que garante a integridade dos dados atrav√©s de uma arquitetura orientada a eventos.

### Requisitos Atendidos

| Requisito | Implementa√ß√£o e Garantia de Integridade |
| :--- | :--- |
| **Microsservi√ßo Independente** | O servi√ßo de `Balances` √© um projeto Polylith isolado, com seu pr√≥prio ciclo de vida, banco de dados e porta (**3003**), garantindo o desacoplamento f√≠sico e l√≥gico. |
| **Consist√™ncia Eventual** | A integridade entre o `Wallet Core` e o `Balances` √© mantida via Kafka. O fluxo garante que qualquer altera√ß√£o de saldo no Core seja propagada de forma ass√≠ncrona e confi√°vel. |
| **Persist√™ncia de Balances** | Diferente de uma simples cache, o Balances possui seu pr√≥prio banco PostgreSQL (`balances-db`), permitindo consultas hist√≥ricas e recupera√ß√£o de estado independentemente da Wallet. |
| **Automa√ß√£o Total (Seed & Migrations)** | O sistema √© "zero touch". Ao subir o Docker, as migrations do Wallet e do Balances rodam em paralelo, e o Wallet popula dados iniciais (Seed) que fluem automaticamente at√© o Balances via eventos. |
| **Contrato de Dados** | A estrutura de mensagens no Kafka segue um padr√£o estrito, garantindo que o consumidor de Balances processe apenas informa√ß√µes v√°lidas para atualiza√ß√£o de saldo. |
| **Documenta√ß√£o Viva** | O arquivo `requests.http` foi estendido para incluir testes de ponta a ponta que validam a integridade do fluxo desde a transa√ß√£o at√© a consulta no novo microsservi√ßo. |

### Fluxo de Integridade de Ponta a Ponta
1. **Wallet Core** executa uma transa√ß√£o ACID no Postgres.
2. Um evento `BalanceUpdated` √© emitido com o **estado final** do saldo.
3. O **Balances Service** consome o evento e realiza um `upsert` at√¥mico no seu banco.
4. O usu√°rio consulta `GET /balances/{id}` e recebe o dado projetado e persistido especificamente para leitura.

---


## üöÄ Como Rodar

### Pr√©-requisitos

* Docker & Docker Compose
* Clojure CLI
* Ferramenta `poly` (opcional, mas recomendada)

### 1. Subir Toda a Aplica√ß√£o (Docker)

Para rodar todos os microsservi√ßos (Wallet Core + Balances + Infra) de uma vez:

```bash
docker compose up -d
```

**O que acontece automaticamente:**
1. Os containers sobem (Postgres, Kafka, Zookeeper, Wallet, Balances).
2. O **Wallet Core** detecta que o banco est√° vazio e roda o **Seed Autom√°tico**.
   - Cria Clientes e Contas.
   - Faz transa√ß√µes que geram eventos.
3. O **Balances Service** recebe os eventos e atualiza seu pr√≥prio banco.

### 2. Rodar Localmente (Modo Desenvolvimento)

Se voc√™ quiser rodar um dos servi√ßos via terminal (REPL):

**Wallet Core:**
```bash
cd projects/wallet
clojure -M -m br.com.eda.wallet-api.core
```

**Balances Service:**
```bash
cd projects/balances
clojure -M -m br.com.eda.balances-api.core
```

A API do **Wallet** estar√° dispon√≠vel em: `http://localhost:8080`
A API do **Balances** estar√° dispon√≠vel em: `http://localhost:3003`

## üß™ Testando a API

Para facilitar os testes, eu preparei o arquivo `requests.http` (requer extens√£o **REST Client**), mas voc√™ tamb√©m pode utilizar os comandos `curl` abaixo.

### 1. Health Check
Verifica se a API est√° online.
```bash
curl -X GET http://localhost:8080/health
```

### 2. Clientes
#### Criar Cliente
```bash
curl -X POST http://localhost:8080/clients \
  -H "Content-Type: application/json" \
  -d '{"name": "Neo", "email": "neo@matrix.com"}'
```

#### Listar Clientes
```bash
curl -X GET http://localhost:8080/clients
```

### 3. Contas
#### Criar Conta
Use o `id` retornado na cria√ß√£o do cliente.
```bash
curl -X POST http://localhost:8080/accounts \
  -H "Content-Type: application/json" \
  -d '{"client_id": "UUID_DO_CLIENTE"}'
```

#### Listar Contas
```bash
curl -X GET http://localhost:8080/accounts
```

#### Ver Saldo
```bash
curl -X GET http://localhost:8080/accounts/UUID_DA_CONTA/balance
```

### 4. Transa√ß√µes
#### Realizar Transfer√™ncia
Isso debita da origem, credita no destino (Atomicamente) e publica no Kafka.
```bash
curl -X POST http://localhost:8080/transactions \
  -H "Content-Type: application/json" \
  -d '{
    "account_id_from": "UUID_CONTA_ORIGEM",
    "account_id_to": "UUID_CONTA_DESTINO",
    "amount": 100
  }'
```

#### Ver Extrato (Hist√≥rico)
```bash
curl -X GET http://localhost:8080/accounts/UUID_DA_CONTA/transactions
```

### 5. Balances Service (Microsservi√ßo Novo)
#### Consultar Saldo
Este endpoint consulta o banco de dados exclusivo do servi√ßo de Balances.
```bash
curl -X GET http://localhost:3003/balances/UUID_DA_CONTA
# Exemplo de resposta: {"account_id":"...","balance":100,"updated_at":"..."}
```

## üõ† Desenvolvimento

Para rodar os testes de todos os componentes:

```bash
clojure -M:poly test

```

Para verificar a integridade do workspace:

```bash
clojure -M:poly check

```

---

## ‚ö†Ô∏è Trade-offs e Melhorias que Eu Planejo

### Consist√™ncia de Dados (The Dual Write Problem)
Na minha implementa√ß√£o atual do componente `Transaction`, eu utilizei uma abordagem pragm√°tica para o escopo deste exerc√≠cio:
1. Commit da transa√ß√£o no PostgreSQL (Atomicidade garantida via `jdbc/with-transaction`).
2. Publica√ß√£o do evento no Kafka (Fire and forget).

**Cen√°rio de Risco:**
Existe uma janela de falha te√≥rica (milissegundos) entre o commit do banco e a publica√ß√£o no Kafka. Se o processo da aplica√ß√£o for encerrado abruptamente (Crash/OOM/Falha de Rede) exatamente neste intervalo, o sistema entrar√° em estado inconsistente (Dinheiro debitado, mas evento n√£o emitido).

**Solu√ß√£o para Produ√ß√£o:**
Para evoluir este projeto para um ambiente cr√≠tico, a solu√ß√£o recomendada seria implementar o **Transactional Outbox Pattern**:
1. Persistir o evento em uma tabela `outbox` dentro da mesma transa√ß√£o SQL da transfer√™ncia.
2. Utilizar um processo ass√≠ncrono (Relay ou CDC com Debezium) para ler a tabela `outbox` e publicar no Kafka com garantia de entrega *At-Least-Once*.

### Outras Melhorias
* **Idempot√™ncia no Consumo:** Garantir que os consumidores Kafka lidem com mensagens duplicadas.
* **Schema Registry:** Adotar Avro ou JSON Schema para contrato estrito de mensagens.
* **Distributed Tracing:** Implementar OpenTelemetry para rastrear o fluxo entre API -> DB -> Kafka.

---

### üìä O Fluxo de Sequ√™ncia (Passo a Passo)

Neste diagrama, eu mostro exatamente o que acontece desde o momento em que o usu√°rio chama a API at√© o Worker processar o evento.

```mermaid
sequenceDiagram
    autonumber
    participant U as Usu√°rio (HTTP)
    participant API as Wallet API (App)
    participant DB as Postgres (Wallet)
    participant K as Kafka
    participant B as Balances Service
    participant DB2 as Postgres (Balances)

    Note over U, API: 1. In√≠cio da Requisi√ß√£o
    U->>API: POST /transactions
    
    activate API
    
    Note over API, DB: 2. Unit of Work (At√¥mico)
    API->>DB: BEGIN TRANSACTION
    activate DB
    API->>DB: Debita Conta Origem
    API->>DB: Credita Conta Destino
    API->>DB: COMMIT
    deactivate DB
    
    Note over API, K: 3. Notifica√ß√£o (Fire & Forget)
    API->>K: Produce "BalanceUpdated"
    
    API-->>U: 201 Created (Transa√ß√£o Conclu√≠da)
    deactivate API
    
    Note over K, B: 4. Processamento Ass√≠ncrono (Event Driven)
    loop Polling
        B->>K: Poll (Novas mensagens?)
        K-->>B: Evento: {Payload: ...}
    end
    
    activate B
    Note over B, DB2: 5. Atualiza√ß√£o de Leitura
    B->>DB2: Upsert Balance (Novo Saldo)
    deactivate B
```

---

### üìù Detalhando as Etapas

Aqui eu explico o que acontece em cada fase numerada no diagrama:

#### 1. A Solicita√ß√£o (S√≠ncrono)

O cliente (pode ser um App Mobile, Frontend ou Postman) envia o JSON pedindo a transfer√™ncia.

* **Respons√°vel:** `bases/wallet-api` (Handlers).
* **Valida√ß√£o:** O `Malli` verifica se os IDs s√£o strings e se o valor √© positivo.

#### 2. O Cora√ß√£o do Sistema (ACID)

√â aqui que a m√°gica acontece. Eu usei `jdbc/with-transaction` para garantir a integridade financeira.

* **Onde:** `components/transaction`.
* **A√ß√£o:** O dinheiro sai de A e vai para B matematicamente.
* **Garantia:** Se a luz acabar na linha do "D√©bito", o "Cr√©dito" nunca acontece e o banco faz *Rollback* autom√°tico. **O dinheiro est√° seguro.**

#### 3. A Promessa (Eventual Consistency)

Imediatamente ap√≥s o banco confirmar "OK, gravei", a API avisa o Kafka.

#### 4. O Microsservi√ßo de Balances (Consumidor)

Em um container separado, o **Balances Service** acorda ao receber o evento.

* **Onde:** `bases/balances-api` (Consumer).
* **A√ß√£o:** Ele deserializa o evento `BalanceUpdated`.
* **Efeito:** Ele atualiza a tabela `balances` no banco dedicado. Isso permite que o saldo seja consultado rapidamente sem sobrecarregar o banco principal de transa√ß√µes.

### Por que eu escolhi separar assim?

Se o passo **4** falhar (ex: servi√ßo de Balances fora do ar), a transa√ß√£o **n√£o √© cancelada**. O dinheiro j√° foi movido no passo **2**. O Consumers apenas reprocessa o evento quando o servi√ßo voltar. Isso garante **Alta Disponibilidade** para a Wallet.



---

Para transformar meu projeto acad√™mico `eda-study` em uma arquitetura de **Fintech Real ("Battle-Tested")**, eu precisaria endere√ßar problemas que s√≥ aparecem em escala e com dinheiro de verdade em jogo: **Fraude, Consist√™ncia Eventual, Lat√™ncia e Escalabilidade de Leitura.**

Abaixo, eu ilustro como esse sistema evoluiria na vida real.

### üèõ A Arquitetura Fintech Realista (CQRS + Event Sourcing + Sagas)

Neste cen√°rio, o fluxo n√£o √© apenas "Mover dinheiro e Logar". O evento `TransactionCreated` dispara uma rea√ß√£o em cadeia em v√°rios departamentos (Microsservi√ßos).

#### 1. O Diagrama de Fluxo "Battle-Tested"

```mermaid
graph TD
    User[üì± App do Usu√°rio]
    API[üõ°Ô∏è Wallet API Gateway]
    
    subgraph "Core Transacional (Write Side)"
        DB_Write[(üêò Postgres Master)]
        Outbox[üì¶ Tabela Outbox]
    end
    
    subgraph "Event Bus"
        Kafka{Apache Kafka}
        Debezium[CDC Connector]
    end
    
    subgraph "Consumers (Workers Especializados)"
        Fraud[üïµÔ∏è Anti-Fraud Service]
        Ledger[üìí Ledger Imut√°vel]
        Notif[üîî Notification Service]
        Projector[üìΩÔ∏è Read Model Projector]
    end
    
    subgraph "Leitura Otimizada (Read Side)"
        DB_Read[(üçÉ MongoDB / Elastic)]
    end

    %% Fluxo
    User -->|"1. Idempotency-Key + Payload"| API
    API -->|"2. Valida√ß√£o + Rate Limit"| DB_Write
    DB_Write -->|"3. Commit (Transa√ß√£o + Evento Outbox)"| Outbox
    
    Outbox -.->|"4. CDC (Leitura de Log)"| Debezium
    Debezium -->|"5. Publica Evento"| Kafka
    
    Kafka -->|"6a. Analisa Risco"| Fraud
    Kafka -->|"6b. Auditoria Cont√°bil"| Ledger
    Kafka -->|"6c. Push/Email"| Notif
    Kafka -->|"6d. Atualiza Visualiza√ß√£o"| Projector
    
    Projector -->|"7. Grava Extrato Otimizado"| DB_Read
    User -.->|"8. Consulta Extrato (R√°pido)"| DB_Read

```

---

### üß† Deep Dive: Minhas Reflex√µes sobre Engenharia e Arquitetura

Vou detalhar as camadas que eu adicionaria e por que elas s√£o obrigat√≥rias numa Fintech real.

#### 1. A Entrada: Idempot√™ncia e Rate Limiting

No meu c√≥digo atual, se o usu√°rio clicar 2 vezes no bot√£o "Transferir", o dinheiro sai 2 vezes.

* **Realidade:** O App envia um Header `Idempotency-Key` (um UUID gerado no celular).
* **Engenharia:** A API verifica no Redis se essa chave j√° foi processada. Se sim, retorna o resultado anterior cacheado, sem tocar no Postgres. Isso evita **Double Spending** em redes inst√°veis.

#### 2. O Core: Transactional Outbox (CDC)

Como eu mencionei antes, o c√≥digo atual tem o risco de escrever no banco e falhar no Kafka.

* **Realidade:** Usamos **CDC (Change Data Capture)**. Ferramentas como **Debezium** leem o log bin√°rio do Postgres (WAL) e garantem que *cada linha inserida no banco vire um evento no Kafka*.
* **Benef√≠cio:** Zero perda de dados. O banco √© a fonte da verdade, o Kafka √© o reflexo fiel.

#### 3. O C√©rebro: Fraude e Sagas (Compensating Transactions)

E se a transfer√™ncia for aprovada pelo banco, mas o Worker de Fraude (`Fraud`) detectar que √© uma lavagem de dinheiro 1 segundo depois? O dinheiro j√° saiu!

* **Arquitetura:** Padr√£o **Saga (Coreografia)**.
* **Fluxo:**
1. Core: Move dinheiro (Status: `PENDING`).
2. Kafka: Publica `TransactionPending`.
3. Fraud Worker: Analisa. Se detectar fraude, publica evento `FraudDetected`.
4. Core (Consumer): Escuta `FraudDetected` e executa uma **Transa√ß√£o de Compensa√ß√£o** (Estorno/Refund) e marca como `REJECTED`.



#### 4. A Vis√£o: CQRS (Command Query Responsibility Segregation)

No meu c√≥digo atual, eu uso `h/select` na mesma tabela `transactions` que recebe escritas.

* **O Problema:** Num dia de pagamento (dia 5), milh√µes de pessoas abrem o app para ver o saldo (Leitura), travando o banco para quem quer transferir (Escrita).
* **Realidade:** Separamos leitura e escrita.
* **Write Side (Postgres):** Normalizado, r√≠gido, focado em integridade.
* **Read Side (NoSQL/Elastic):** O Worker `Projector` pega o evento e monta um JSON pronto para a tela do celular ("Extrato Bonito").


* **Engenharia:** O App consulta o NoSQL. √â absurdamente r√°pido e barato, e nunca trava as transa√ß√µes.

#### 5. O Livro Raz√£o: Ledger Imut√°vel

A tabela `transactions` do meu projeto √© mut√°vel. Numa fintech, contadores precisam de um hist√≥rico que prova que o saldo de A + B √© igual ao total de dinheiro no banco.

* **Realidade:** O Worker `Ledger` grava num banco espec√≠fico (como **Datomic** ou **XTDB** em Clojure) que suporta auditoria temporal e imutabilidade criptogr√°fica.

---

### üß™ Por que eu escolhi o Clojure?

A stack que eu escolhi (**Clojure + Kafka**) √© a "Arma Secreta" do Nubank e outras gigantes. Vou explicar por qu√™:

1. **Imutabilidade por Padr√£o:** Em sistemas concorrentes (milhares de transa√ß√µes/segundo), n√£o ter que lidar com objetos mudando de estado na mem√≥ria evita uma classe inteira de bugs.
2. **EDN (Extensible Data Notation):** O Clojure trafega dados como mapas. Diferente do Java (que precisa converter JSON -> Objeto -> DTO -> DAO), o Clojure processa o dado "nu e cru" dos Workers de forma extremamente perform√°tica.
3. **Datomic/XTDB:** Bancos de dados feitos em Clojure que resolvem o problema de auditoria nativamente.

**Resumo da Evolu√ß√£o do meu projeto:**
Meu projeto atual √© o **"MVP Funcional"**.
A vers√£o Fintech Real adiciona: **Idempot√™ncia (Seguran√ßa)**, **CDC (Consist√™ncia)**, **Sagas (Revers√£o)** e **CQRS (Escalabilidade)**.